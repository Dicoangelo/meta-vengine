# Autonomous CLI Routing System

**Version:** 1.0.0
**Status:** Production-Ready
**Last Updated:** 2026-01-18

---

## üéØ Overview

An intelligent model routing system for Claude CLI that automatically selects the optimal model (Haiku, Sonnet, or Opus) based on query complexity and performance history. The system uses the DQ (Decision Quality) framework to make routing decisions and continuously improves through research integration and automated optimization.

### Key Features

- **ü§ñ Autonomous Routing**: DQ-powered model selection (validity 40% + specificity 30% + correctness 30%)
- **üìä Performance Tracking**: Real-time metrics on accuracy, cost efficiency, and latency
- **üß™ A/B Testing**: Statistical validation of optimization proposals
- **üîÑ Auto-Update**: Self-improving system with production validation
- **üìö Research-Driven**: arXiv integration for baseline enhancements
- **üîÅ Feedback Loop**: Automated learning from command success/failure

### Performance Targets

| Metric | Target | Typical Performance |
|--------|--------|---------------------|
| Routing Accuracy | ‚â•75% | 80-85% |
| Cost Reduction | ‚â•20% vs random | 20-30% |
| Routing Latency (p95) | <50ms | 35-45ms |
| Avg DQ Score | ‚â•0.70 | 0.72-0.78 |

---

## üöÄ Quick Start

### First-Time Setup

```bash
# 1. System is already activated via init.sh
source ~/.claude/init.sh

# 2. Test basic routing
claude -p "what is 2+2"
# Expected: [DQ:0.XX C:0.XX] ‚Üí haiku

# 3. Enable automated feedback (learns from failures)
ai-feedback-enable

# 4. Install automation (recommended)
routing-cron install standard

# 5. Verify installation
routing-dash
```

### Daily Usage

```bash
# Use claude command normally - routing is automatic
claude -p "your question here"

# Manual override if needed
claude --model opus -p "force opus for this query"

# Check performance anytime
routing-dash
```

---

## üìñ Core Commands

### Routing Commands

```bash
# Use AI routing (automatic)
claude -p "your query"              # Auto-routes via DQ scoring
ai "your query"                     # Same, via ai() function

# Manual override
claude --model haiku -p "query"     # Force haiku
claude --model sonnet -p "query"    # Force sonnet
claude --model opus -p "query"      # Force opus

# Legacy shortcuts (bypass routing)
cq -p "query"                       # Always use haiku
cc -p "query"                       # Always use sonnet
co -p "query"                       # Always use opus
```

### Monitoring & Feedback

```bash
# Dashboard & Reports
routing-dash                        # Real-time performance view
routing-report 7                    # Weekly report
routing-report 30                   # Monthly report
routing-targets                     # Check if targets met

# Feedback (improves routing)
ai-good "query prefix"              # Mark success
ai-bad "query prefix"               # Mark failure
ai-feedback-enable                  # Enable auto-feedback
ai-feedback-disable                 # Disable auto-feedback

# View logs
tail -f ~/.claude/data/ai-routing.log
cat ~/.claude/data/routing-metrics.jsonl
```

### Testing & Validation

```bash
# Run test suite
python3 ~/researchgravity/routing-test-suite.py all

# Individual test suites
python3 ~/researchgravity/routing-test-suite.py regression    # 15 query tests
python3 ~/researchgravity/routing-test-suite.py performance  # Latency checks
python3 ~/researchgravity/routing-test-suite.py validation   # System health

# Export test results
python3 ~/researchgravity/routing-test-suite.py all --format json --output results.json
```

### Optimization & A/B Testing

```bash
# Generate optimization proposals
meta-analyzer propose --domain routing --days 30

# A/B Testing
routing-metrics.py ab-test create --config experiment.json
routing-metrics.py ab-test status                          # View active tests
routing-metrics.py ab-test analyze --experiment exp-001   # Check results
routing-metrics.py ab-test apply --experiment exp-001     # Apply winner

# View all experiments
routing-metrics.py ab-test list
```

### Automation & Auto-Update

```bash
# Cron Automation
routing-cron install standard       # Install standard profile
routing-cron status                # Check installation
routing-cron test daily            # Test a job manually
routing-cron logs daily            # View logs
routing-cron uninstall             # Remove all jobs

# Auto-Update System
routing-auto status                # Check readiness & status
routing-auto enable                # Enable auto-updates
routing-auto approve               # Approve first update
routing-auto check                 # Check for updates
routing-auto apply                 # Apply updates manually
routing-auto disable               # Disable auto-updates
```

### Research Integration

```bash
# Fetch recent papers
cd ~/researchgravity
python3 routing-research-sync.py fetch-papers \
  --query "LLM routing" --days 90 --output papers.json

# Extract insights (LLM-assisted)
python3 routing-research-sync.py extract-insights \
  --papers papers.json --model sonnet --output insights.json

# Preview baseline updates
python3 routing-research-sync.py update-baselines \
  --insights insights.json --dry-run

# Apply updates
python3 routing-research-sync.py update-baselines \
  --insights insights.json --apply

# Trace parameter origin
python3 routing-research-sync.py trace \
  --parameter "complexity_thresholds.haiku.range[1]"
```

---

## üèóÔ∏è Architecture

### System Components

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     USER COMMAND                            ‚îÇ
‚îÇ                   claude "query"                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              CLAUDE-WRAPPER.SH                              ‚îÇ
‚îÇ  - Intercepts all claude commands                           ‚îÇ
‚îÇ  - Checks for manual --model override                       ‚îÇ
‚îÇ  - Passes to DQ scorer if no override                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                DQ-SCORER.JS (Kernel)                        ‚îÇ
‚îÇ  - Loads baselines.json                                     ‚îÇ
‚îÇ  - Analyzes complexity (0.0-1.0 scale)                      ‚îÇ
‚îÇ  - Calculates DQ score:                                     ‚îÇ
‚îÇ    ‚Ä¢ Validity (40%)                                         ‚îÇ
‚îÇ    ‚Ä¢ Specificity (30%)                                      ‚îÇ
‚îÇ    ‚Ä¢ Correctness (30%)                                      ‚îÇ
‚îÇ  - Selects optimal model                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              MODEL SELECTION                                ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Haiku   (C: 0.00-0.30)  Simple, quick, cheap              ‚îÇ
‚îÇ  Sonnet  (C: 0.30-0.70)  Code, analysis, moderate          ‚îÇ
‚îÇ  Opus    (C: 0.70-1.00)  Architecture, complex reasoning   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              METRICS & FEEDBACK                             ‚îÇ
‚îÇ  - routing-metrics.jsonl (all decisions logged)             ‚îÇ
‚îÇ  - dq-scores.jsonl (with feedback)                          ‚îÇ
‚îÇ  - Automated feedback loop (shell hook)                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         CONTINUOUS IMPROVEMENT LOOP                         ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Daily:   Metrics reports                                   ‚îÇ
‚îÇ  Weekly:  Research paper sync, target validation           ‚îÇ
‚îÇ  Monthly: Meta-analyzer proposals, A/B tests               ‚îÇ
‚îÇ  Auto:    Apply validated optimizations (30d stable)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Data Flow

```
Query ‚Üí Complexity Analysis ‚Üí DQ Scoring ‚Üí Model Selection ‚Üí Execution
  ‚Üì                                                             ‚Üì
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Feedback Loop ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
                      Pattern Analysis
                            ‚Üì
                    Optimization Proposals
                            ‚Üì
                       A/B Testing
                            ‚Üì
                  Validated Improvements
                            ‚Üì
                    Baseline Updates
```

---

## üìÅ File Structure

### Core Files

```
~/.claude/
‚îú‚îÄ‚îÄ kernel/
‚îÇ   ‚îú‚îÄ‚îÄ dq-scorer.js                 # DQ routing engine
‚îÇ   ‚îú‚îÄ‚îÄ baselines.json               # Thresholds + research lineage
‚îÇ   ‚îú‚îÄ‚îÄ coevo-config.json            # Meta-analyzer configuration
‚îÇ   ‚îî‚îÄ‚îÄ auto-update-config.json      # Auto-update settings
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ claude-wrapper.sh            # CLI interceptor (activates routing)
‚îÇ   ‚îú‚îÄ‚îÄ smart-route.sh               # ai() function + feedback
‚îÇ   ‚îú‚îÄ‚îÄ routing-dashboard.sh         # Performance dashboard
‚îÇ   ‚îú‚îÄ‚îÄ routing-cron-setup.sh        # Automation installer
‚îÇ   ‚îú‚îÄ‚îÄ routing-auto-update.sh       # Auto-update system
‚îÇ   ‚îî‚îÄ‚îÄ meta-analyzer.py             # Pattern analysis + proposals
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ routing-metrics.jsonl        # All routing decisions
‚îÇ   ‚îú‚îÄ‚îÄ ai-routing.log               # Activity log
‚îÇ   ‚îî‚îÄ‚îÄ ab-experiments/              # A/B test configurations
‚îÇ
‚îî‚îÄ‚îÄ logs/
    ‚îú‚îÄ‚îÄ routing-daily.log            # Daily metrics
    ‚îú‚îÄ‚îÄ routing-research.log         # Research sync
    ‚îú‚îÄ‚îÄ routing-targets.log          # Target validation
    ‚îî‚îÄ‚îÄ routing-proposals-*.json     # Monthly proposals
```

### ResearchGravity Files

```
~/researchgravity/
‚îú‚îÄ‚îÄ routing-metrics.py               # Metrics + A/B testing
‚îú‚îÄ‚îÄ routing-research-sync.py         # arXiv integration
‚îú‚îÄ‚îÄ routing-test-suite.py            # Comprehensive tests
‚îú‚îÄ‚îÄ ROUTING_RESEARCH_WORKFLOW.md     # Research integration guide
‚îî‚îÄ‚îÄ ROUTING_IMPLEMENTATION_COMPLETE.md  # Phase 1-3 docs
```

---

## üéõÔ∏è Configuration

### Baselines Configuration

**File:** `~/.claude/kernel/baselines.json`

```json
{
  "version": "1.0.0",
  "last_updated": "2026-01-18T00:00:00Z",

  "complexity_thresholds": {
    "haiku": {
      "range": [0.0, 0.30],
      "optimal": [0.0, 0.25],
      "description": "Simple queries, formatting, quick Q&A"
    },
    "sonnet": {
      "range": [0.30, 0.70],
      "optimal": [0.30, 0.60],
      "description": "Code generation, analysis, reasoning"
    },
    "opus": {
      "range": [0.70, 1.0],
      "optimal": [0.70, 1.0],
      "description": "Architecture, complex reasoning, research"
    }
  },

  "dq_weights": {
    "validity": 0.4,
    "specificity": 0.3,
    "correctness": 0.3
  },

  "performance_targets": {
    "routing_accuracy": 0.75,
    "cost_reduction_vs_random": 0.20,
    "routing_latency_ms": 50,
    "avg_dq_score": 0.70
  }
}
```

### Cron Profiles

**Minimal:**
- Daily metrics reports
- Weekly target validation

**Standard (Recommended):**
- Daily metrics reports
- Weekly target validation
- Weekly research paper sync
- Monthly meta-analyzer proposals

**Full:**
- All standard features
- Monthly full research cycle with paper integration

### Auto-Update Safety Settings

```json
{
  "enabled": false,
  "approved_by_user": false,
  "stability_period_days": 30,
  "min_queries_required": 200,
  "targets_must_meet_consecutively": 7,
  "auto_rollback_on_drop": true,
  "rollback_threshold_pct": 0.10,
  "require_ab_test_validation": true,
  "max_auto_updates_per_month": 2
}
```

---

## üî¨ Research Integration

### Research ‚Üí Baseline Pipeline

1. **Fetch Papers** (Weekly, automated)
   - arXiv cs.AI category
   - Keywords: "LLM routing", "model selection", "adaptive inference"
   - Last 7-90 days

2. **Extract Insights** (LLM-assisted)
   - Claude Sonnet analyzes abstracts
   - Extracts: thresholds, cost insights, strategies
   - Assigns confidence score

3. **Validate Changes**
   - Only apply if >5% improvement
   - Confidence score ‚â•0.6
   - Dry-run preview first

4. **Track Lineage**
   - Full provenance: paper ‚Üí insight ‚Üí baseline change
   - Traceable via `trace` command

### Paper Lineage Example

```json
{
  "target": "complexity_thresholds.haiku.range[1]",
  "old_value": 0.30,
  "new_value": 0.32,
  "source_paper": "arXiv:2601.XXXXX",
  "paper_title": "Optimal LLM Routing via Complexity Thresholds",
  "rationale": "92% accuracy observed for haiku at complexity 0.30-0.32",
  "confidence": 0.82,
  "applied": "2026-01-18T14:30:00Z"
}
```

---

## üß™ A/B Testing Guide

### Creating an Experiment

**1. Create experiment config:**

```json
{
  "name": "Haiku threshold adjustment",
  "control": {
    "complexity_thresholds.haiku.range[1]": 0.30
  },
  "variant": {
    "complexity_thresholds.haiku.range[1]": 0.32
  },
  "split": 0.5,
  "primary_metric": "dq_score",
  "secondary_metrics": ["cost_per_query", "accuracy"],
  "min_samples": 100,
  "success_criteria": {
    "min_improvement": 0.05,
    "max_p_value": 0.05
  }
}
```

**2. Launch experiment:**

```bash
python3 ~/researchgravity/routing-metrics.py ab-test create --config experiment.json
```

**3. Monitor progress:**

```bash
routing-metrics.py ab-test status
# Shows: samples collected, early results, time to completion
```

**4. Analyze results:**

```bash
routing-metrics.py ab-test analyze --experiment exp-001
```

**5. Apply if successful:**

```bash
# Dry run first
routing-metrics.py ab-test apply --experiment exp-001 --dry-run

# Apply to baselines
routing-metrics.py ab-test apply --experiment exp-001
```

### Interpreting Results

- **p-value < 0.05**: Statistically significant
- **Improvement > 5%**: Meaningful improvement
- **Samples ‚â• 100**: Sufficient data for decision

---

## üõ†Ô∏è Troubleshooting

### Issue: Routing not activating

```bash
# Check if wrapper is installed
type claude
# Should show: claude is aliased to `~/.claude/scripts/claude-wrapper.sh'

# If not, re-source init.sh
source ~/.claude/init.sh

# Verify DQ scorer works
node ~/.claude/kernel/dq-scorer.js route "test query"
# Should output JSON with model selection
```

### Issue: Always routing to same model

```bash
# Check baselines are loaded
cat ~/.claude/kernel/baselines.json | jq .complexity_thresholds

# Check DQ scorer logs
tail -20 ~/.claude/data/ai-routing.log

# Test with different complexity queries
claude -p "what is 2+2"                    # Should ‚Üí haiku
claude -p "implement binary search"        # Should ‚Üí sonnet
claude -p "design distributed system"      # Should ‚Üí opus
```

### Issue: High routing latency

```bash
# Run performance test
python3 ~/researchgravity/routing-test-suite.py performance

# Check if baselines file is too large
ls -lh ~/.claude/kernel/baselines.json

# Expected: <50KB, load time <10ms
```

### Issue: Auto-update not activating

```bash
# Check status and requirements
routing-auto status

# Requirements:
# - 30 days of operation
# - 200+ queries processed
# - All targets met
# - User approval given

# To approve:
routing-auto approve
```

### Issue: Cron jobs not running

```bash
# Check installation
crontab -l | grep routing

# Check logs
routing-cron logs all

# Test manually
routing-cron test daily

# Reinstall if needed
routing-cron uninstall
routing-cron install standard
```

### Issue: A/B test not recording data

```bash
# Check experiment is active
routing-metrics.py ab-test list

# Check experiment configuration
cat ~/.claude/data/ab-experiments/exp-*.json | jq .active
# Should be: true

# Verify metrics are being logged
tail ~/.claude/data/routing-metrics.jsonl
```

---

## üìä Understanding Metrics

### Dashboard Output

```
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  ü§ñ AUTONOMOUS ROUTING DASHBOARD
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚úì Status: Active

Period: Last 7 days
Total Queries: 127

üìä Model Distribution:
  haiku   : 32.0%
  sonnet  : 53.0%
  opus    : 15.0%

üìà Performance Metrics:
  Avg DQ Score:   0.742
  Avg Complexity: 0.423

‚è±Ô∏è  Routing Latency:
  Average: 27.3ms
  p50:     24.1ms
  p95:     42.8ms

üéØ Quality & Cost:
  Accuracy:       78.5%
  Cost Reduction: 23.2% vs random

‚úÖ Targets Met:
  4/4 targets
    ‚úì accuracy
    ‚úì cost_reduction
    ‚úì avg_dq
    ‚úì p95_latency
```

### Metric Definitions

**Routing Accuracy**: % of queries where selected model was optimal (based on feedback)

**Cost Reduction**: Savings vs random model selection (33% each model)

**Routing Latency**: Time from query ‚Üí model selection decision

**DQ Score**: Combined quality score (validity + specificity + correctness)

**Complexity**: Query difficulty on 0-1 scale
- 0.0-0.3: Simple (definitions, facts, formatting)
- 0.3-0.7: Moderate (coding, analysis, reasoning)
- 0.7-1.0: Complex (architecture, research, multi-step)

---

## üéì Best Practices

### For Daily Use

1. **Let routing decide** - Don't manually override unless necessary
2. **Provide feedback** - Use `ai-good`/`ai-bad` for important queries
3. **Monitor weekly** - Check `routing-dash` every Friday
4. **Trust the system** - It learns from your patterns

### For Optimization

1. **Wait for data** - Need 100+ queries before optimizing
2. **Use A/B tests** - Don't apply proposals blindly
3. **Review lineage** - Understand why baselines changed
4. **Small adjustments** - Prefer ¬±2% over large jumps

### For Maintenance

1. **Weekly checks** - Review dashboard and logs
2. **Monthly reviews** - Examine proposals and A/B results
3. **Quarterly audits** - Run full test suite
4. **Keep updated** - Let research sync run weekly

---

## üîê Privacy & Security

### Data Collection

**Local Only:**
- All metrics stored in `~/.claude/data/`
- No external transmission
- Full control over retention

**What's Tracked:**
- Query hash (MD5, not plaintext)
- Model selected
- Complexity score
- DQ scores
- Latency
- Success/failure feedback

**What's NOT Tracked:**
- Full query text (only first 50 chars for logs)
- Personal information
- API keys or credentials

### Data Retention

```bash
# View current data size
du -sh ~/.claude/data/

# Archive old metrics (keep last 90 days)
find ~/.claude/data/ -name "*.jsonl" -mtime +90 -exec gzip {} \;

# Clear test data
rm ~/.claude/data/ab-experiments/exp-test-*.json
```

---

## üöÄ Advanced Usage

### Custom Complexity Scoring

Edit `~/.claude/kernel/dq-scorer.js` to adjust complexity heuristics:

```javascript
// Add domain-specific keywords
const COMPLEXITY_INDICATORS = {
  high: ['architect', 'design system', 'distributed', 'scale'],
  medium: ['implement', 'refactor', 'optimize', 'analyze'],
  low: ['what is', 'define', 'format', 'convert']
};
```

### Custom Baselines

```bash
# Create custom baseline profile
cp ~/.claude/kernel/baselines.json ~/.claude/kernel/baselines-custom.json

# Edit thresholds
vim ~/.claude/kernel/baselines-custom.json

# Test with custom baselines
node ~/.claude/kernel/dq-scorer.js route "test" --baselines custom
```

### Export Metrics for Analysis

```bash
# Export to CSV
python3 ~/researchgravity/routing-metrics.py export --days 30 --format csv --output metrics.csv

# Load in Python
import pandas as pd
df = pd.read_csv('metrics.csv')
df.groupby('model')['dq'].mean()
```

---

## üìö Additional Resources

### Documentation

- **Phase 1-3:** `~/researchgravity/ROUTING_IMPLEMENTATION_COMPLETE.md`
- **Phase 4-5:** `~/ROUTING_PHASE_4_5_COMPLETE.md`
- **Research Workflow:** `~/researchgravity/ROUTING_RESEARCH_WORKFLOW.md`
- **This File:** `~/.claude/ROUTING_SYSTEM_README.md`

### Research Papers

- **DQ Framework:** [arXiv:2511.15755] MyAntFarm.ai - Multi-agent consensus
- **Complexity Scoring:** [arXiv:2512.14142] Astraea - State-aware LLM scheduling
- **Routing Strategies:** See `baselines.json` research_lineage

### Support

```bash
# View help for any command
routing-cron help
routing-auto help
routing-metrics.py --help

# Check system status
routing-dash
routing-auto status
routing-cron status

# Run diagnostics
python3 ~/researchgravity/routing-test-suite.py all
```

---

## üìà Roadmap

### Planned Enhancements

**Q1 2026:**
- [ ] Ollama integration (4th tier for local/privacy queries)
- [ ] Multi-dimensional complexity scoring
- [ ] Context-aware routing (session history)

**Q2 2026:**
- [ ] Cross-system learning (CLI ‚Üî OS-App)
- [ ] Cost-performance Pareto optimization
- [ ] Real-time dashboard (web UI)

**Q3 2026:**
- [ ] Custom model fine-tuning for routing
- [ ] Industry-specific routing profiles
- [ ] Advanced pattern recognition

---

## üôè Acknowledgments

**Built with:**
- DQ Framework from MyAntFarm.ai [arXiv:2511.15755]
- Astraea scheduling insights [arXiv:2512.14142]
- ResearchGravity for paper integration
- Claude Code for implementation

**Version History:**
- v1.0.0 (2026-01-18): Full autonomous system with auto-update
- v0.3.0 (2026-01-18): Research integration (Phase 3)
- v0.2.0 (2026-01-18): Metrics and baselines (Phase 2)
- v0.1.0 (2026-01-18): Initial DQ routing (Phase 1)

---

**For questions or issues, see troubleshooting section or run: `routing-test-suite.py all`**

**Last Updated:** 2026-01-18
